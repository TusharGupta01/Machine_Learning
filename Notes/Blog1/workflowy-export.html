<!doctype html><html><head><meta charset="utf-8"><style>
      /* Separated from document_view.css to enable use in downloadable
   export files. #cutAndCopyBucket is included for every rule because
   we wwant cut/copied items to be formatted the same way as they
   would be when exported. */

.formattedExport,
#cutAndCopyBucket {
    font-family: 'Helvetica Neue', Arial, Sans-serif;
    color: #333;
    font-size: 13px;
    line-height: 17px;
    /* used to set white-space: pre-wrap here, but that messes up GMail's
       formatting of the export output, so moving that to the name and
       notes separately. */
}

.formattedExport .name, .formattedExport .note,
#cutAndCopyBucket .name, #cutAndCopyBucket .note {
    white-space: pre-wrap;
}

.formattedExport ul,
#cutAndCopyBucket ul{
    list-style: disc;
    /* Needed to reset browser defaults. */
    margin: 0;
    padding: 0;
}

.formattedExport li,
#cutAndCopyBucket li {
    margin: 4px 0 4px 20px;
    /* Needed to reset browser defaults. */
    padding: 0;
}

.formattedExport > .name,
#cutAndCopyBucket > .name {
    font-size: 16px;
    line-height: 21px;
}

.formattedExport > .note,
#cutAndCopyBucket > .note {
    font-size: 13px;
    line-height: 17px;
}

.formattedExport > ul,
#cutAndCopyBucket > ul {
    margin-top: 15px;
}

.formattedExport .name.done,
#cutAndCopyBucket .name.done {
    text-decoration:line-through;
    color:#999;
}

.formattedExport .note,
#cutAndCopyBucket .note {
    font-size: 12px;
    color:#666;
}

      </style></head><body class="formattedExport"><ul><li><span class="name">Machine Learning </span><ul><li><span class="name">Naive Bayes Classifier </span><ul><li><span class="name">The Naive Bayes classifier is a simple probabilistic classifier which is based on Bayes theorem with strong and naive independence assumption. </span><ul><li><span class="name">Naive Bayes comes handy since it can be trained very quickly. </span></li><li><span class="name">Multinomial Naive Bayes is used when the multiple occurrences of  the words matter a lot in the classification problem. Such an example is when we try perform topic classification. </span></li><li><span class="name">The Binarized Multinomial Naive Bayes is used when the frequencies of the words don't play a key role in our classification. Such an example is sentimental Analysis, where it does not really matters how many times someone mentions the word "bad" but rather only the fact that he does. </span></li><li><span class="name">Bernoulli Naive Bayes can be used when in our problem the absence of a particular word matters. For example Bernoulli commonly used in spam or Adult Content Detection with very good results</span></li></ul></li><li><span class="name">Naive Bayes classifier assumes that the features used in the classification are independent. Despite it can be proven that even  </span></li></ul></li></ul></li></ul></body></html>